{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from gensim.models import Word2Vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"MrbBakh/Twitter_Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = dataset[\"train\"][:5000].values()\n",
    "X_test, y_test = dataset[\"test\"][:1000].values()\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.732"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "pred = m.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       507\n",
      "           1       0.76      0.66      0.71       493\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[406, 101],\n",
       "       [167, 326]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1422, 100)\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec(pd.Series(X_train).str.split())\n",
    "print(w2v.wv.vectors.shape)\n",
    "w2v_dict = dict(zip(w2v.wv.index_to_key, w2v.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 222)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = pd.Series(X_train).str.len().max()\n",
    "\n",
    "\n",
    "def sentence_2_vec(txt):\n",
    "    arr = np.zeros((max_len))\n",
    "\n",
    "    for i, c in enumerate(txt):\n",
    "\n",
    "        stoi = w2v.wv.key_to_index.get(c)\n",
    "        arr[i] = w2v.wv.vectors[stoi].mean()\n",
    "    return arr.reshape(1, -1)\n",
    "\n",
    "\n",
    "arr = np.zeros((len(X_train), max_len))\n",
    "\n",
    "\n",
    "for i, ch in enumerate(X_train):\n",
    "    arr[i] = sentence_2_vec(ch)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5056"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = GaussianNB().fit(arr, y_train)\n",
    "pred = m.predict(arr)\n",
    "accuracy_score(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, word2vec, size=100):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array(\n",
    "            [\n",
    "                np.mean(\n",
    "                    [self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)],\n",
    "                    axis=0,\n",
    "                )\n",
    "                for words in X\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.507"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    MeanEmbeddingVectorizer(w2v_dict),\n",
    "    GaussianNB(),\n",
    ")\n",
    "\n",
    "pipeline = pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, word2vec, size=100):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = 100\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of\n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()]\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array(\n",
    "            [\n",
    "                np.mean(\n",
    "                    [\n",
    "                        self.word2vec[w] * self.word2weight[w]\n",
    "                        for w in words\n",
    "                        if w in self.word2vec\n",
    "                    ]\n",
    "                    or [np.zeros(self.dim)],\n",
    "                    axis=0,\n",
    "                )\n",
    "                for words in X\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    TfidfEmbeddingVectorizer(w2v_dict),\n",
    "    GaussianNB(),\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.674"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = make_pipeline(TfidfVectorizer(), KNeighborsClassifier())\n",
    "m.fit(X_train, y_train)\n",
    "pred = m.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.762"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = make_pipeline(TfidfVectorizer(), SVC())\n",
    "m.fit(X_train, y_train)\n",
    "pred = m.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer + NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.671"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, stop_words=\"english\", use_idf=True)\n",
    "m = make_pipeline(\n",
    "    vectorizer,\n",
    "    NMF(n_components=100, random_state=42),\n",
    "    Normalizer(copy=False),\n",
    "    MultinomialNB(alpha=0.01),\n",
    ")\n",
    "m = m.fit(X_train, y_train)\n",
    "pred = m.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "m = m.fit(X_train, y_train)\n",
    "pred = m.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.754"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "LR_pipeline = Pipeline(\n",
    "    steps=[(\"tf\", TfidfVectorizer()), (\"lgrg\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "pgrid_lgrg = {\n",
    "    \"tf__max_features\": [1000, 2000, 3000],\n",
    "    \"tf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"tf__use_idf\": [True, False],\n",
    "    \"lgrg__penalty\": [\"l2\", \"none\"],\n",
    "    \"lgrg__class_weight\": [\"balanced\", None],\n",
    "}\n",
    "\n",
    "gs_lgrg = GridSearchCV(LR_pipeline, pgrid_lgrg, cv=2, n_jobs=-1, verbose=2)\n",
    "gs_lgrg.fit(X_train, y_train)  # Train LR model\n",
    "pred = gs_lgrg.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
